---
---

@article{marzi2024feudal,
abbr={TMLR},
title={Feudal Graph Reinforcement Learning},
author={Tommaso Marzi and Arshjot Singh Khehra and Andrea Cini and Cesare Alippi},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2024},
URL={https://openreview.net/forum?id=wFcyJTik90},
note={},
selected={true},
website = {https://arxiv.org/abs/2304.05099},
ABSTRACT={Graph-based representations and message-passing modular policies constitute prominent approaches to tackling composable control problems in reinforcement learning (RL). However, as shown by recent graph deep learning literature, such local message-passing operators can create information bottlenecks and hinder global coordination. The issue becomes more serious in tasks requiring high-level planning. In this work, we propose a novel methodology, named Feudal Graph Reinforcement Learning (FGRL), that addresses such challenges by relying on hierarchical RL and a pyramidal message-passing architecture. In particular, FGRL defines a hierarchy of policies where high-level commands are propagated from the top of the hierarchy down through a layered graph structure. The bottom layers mimic the morphology of the physical system, while the upper layers correspond to higher-order sub-modules. The resulting agents are then characterized by a committee of policies where actions at a certain level set goals for the level below, thus implementing a hierarchical decision-making structure that can naturally implement task decomposition. We evaluate the proposed framework on a graph clustering problem and MuJoCo locomotion tasks; simulation results show that FGRL compares favorably against relevant baselines. Furthermore, an in-depth analysis of the command propagation mechanism provides evidence that the introduced message-passing scheme favors learning hierarchical decision-making policies.}
}

@Article{e25030394,
abbr={Entropy},
AUTHOR = {Polizzi, Stefano and Marzi, Tommaso and Matteuzzi, Tommaso and Castellani, Gastone and Bazzani, Armando},
TITLE = {Random Walk Approximation for Stochastic Processes on Graphs},
JOURNAL = {Entropy},
VOLUME = {25},
YEAR = {2023},
NUMBER = {3},
ARTICLE-NUMBER = {394},
URL = {https://www.mdpi.com/1099-4300/25/3/394},
website = {https://www.mdpi.com/1099-4300/25/3/394},
PubMedID = {36981283},
ISSN = {1099-4300},
ABSTRACT = {We introduce the Random Walk Approximation (RWA), a new method to approximate the stationary solution of master equations describing stochastic processes taking place on graphs. Our approximation can be used for all processes governed by non-linear master equations without long-range interactions and with a conserved number of entities, which are typical in biological systems, such as gene regulatory or chemical reaction networks, where no exact solution exists. For linear systems, the RWA becomes the exact result obtained from the maximum entropy principle. The RWA allows having a simple analytical, even though approximated, form of the solution, which is global and easier to deal with than the standard System Size Expansion (SSE). Here, we give some theoretically sufficient conditions for the validity of the RWA and estimate the order of error calculated by the approximation with respect to the number of particles. We compare RWA with SSE for two examples, a toy model and the more realistic dual phosphorylation cycle, governed by the same underlying process. Both approximations are compared with the exact integration of the master equation, showing for the RWA good performances of the same order or better than the SSE, even in regions where sufficient conditions are not met.},
DOI = {10.3390/e25030394}
}